// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_DAQ_DNN_H_
#define FLATBUFFERS_GENERATED_DAQ_DNN_H_

#include "flatbuffers/flatbuffers.h"

namespace DNN {

struct Tensor;

struct QuantInfo;

struct Input;

struct CONV_2D;

struct AVERAGE_POOL_2D;

struct MAX_POOL_2D;

struct RELU;

struct SOFTMAX;

struct FULLY_CONNECTED;

struct ADD;

struct CONCATENATION;

struct DEPTHWISE_CONV_2D;

struct BATCH_TO_SPACE_ND;

struct SPACE_TO_BATCH_ND;

struct STRIDED_SLICE;

struct MUL;

struct DEQUANTIZE;

struct LOCAL_RESPONSE_NORMALIZATION;

struct TANH;

struct FLOOR;

struct LOGISTIC;

struct PRELU;

struct POW;

struct NEG;

struct MINIMUM;

struct MAXIMUM;

struct LOG;

struct Layer;

struct Model;

/// Int8 is deprecated, but int8_data in table Tensor is used, since a Tensor just stores value, not care about quantization method
enum class DataType : int8_t {
  Float32 = 0,
  Int8 = 1,
  Int32 = 2,
  Float16 = 3,
  Bool8 = 4,
  QUANT8_ASYMM = 5,
  QUANT8_SYMM = 6,
  QUANT8_SYMM_PER_CHANNEL = 7,
  QUANT16_ASYMM = 8,
  QUANT16_SYMM = 9,
  MIN = Float32,
  MAX = QUANT16_SYMM
};

inline const DataType (&EnumValuesDataType())[10] {
  static const DataType values[] = {
    DataType::Float32,
    DataType::Int8,
    DataType::Int32,
    DataType::Float16,
    DataType::Bool8,
    DataType::QUANT8_ASYMM,
    DataType::QUANT8_SYMM,
    DataType::QUANT8_SYMM_PER_CHANNEL,
    DataType::QUANT16_ASYMM,
    DataType::QUANT16_SYMM
  };
  return values;
}

inline const char * const *EnumNamesDataType() {
  static const char * const names[] = {
    "Float32",
    "Int8",
    "Int32",
    "Float16",
    "Bool8",
    "QUANT8_ASYMM",
    "QUANT8_SYMM",
    "QUANT8_SYMM_PER_CHANNEL",
    "QUANT16_ASYMM",
    "QUANT16_SYMM",
    nullptr
  };
  return names;
}

inline const char *EnumNameDataType(DataType e) {
  if (e < DataType::Float32 || e > DataType::QUANT16_SYMM) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesDataType()[index];
}

enum class FuseCode : int8_t {
  None = 0,
  Relu = 1,
  Relu1 = 2,
  Relu6 = 3,
  MIN = None,
  MAX = Relu6
};

inline const FuseCode (&EnumValuesFuseCode())[4] {
  static const FuseCode values[] = {
    FuseCode::None,
    FuseCode::Relu,
    FuseCode::Relu1,
    FuseCode::Relu6
  };
  return values;
}

inline const char * const *EnumNamesFuseCode() {
  static const char * const names[] = {
    "None",
    "Relu",
    "Relu1",
    "Relu6",
    nullptr
  };
  return names;
}

inline const char *EnumNameFuseCode(FuseCode e) {
  if (e < FuseCode::None || e > FuseCode::Relu6) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesFuseCode()[index];
}

enum class LayerType : int8_t {
  CONV_2D = 0,
  AVERAGE_POOL_2D = 1,
  MAX_POOL_2D = 2,
  RELU = 3,
  SOFTMAX = 4,
  FULLY_CONNECTED = 5,
  ADD = 6,
  CONCATENATION = 7,
  DEPTHWISE_CONV_2D = 8,
  BATCH_TO_SPACE_ND = 9,
  SPACE_TO_BATCH_ND = 10,
  STRIDED_SLICE = 11,
  MUL = 12,
  DEQUANTIZE = 13,
  LOCAL_RESPONSE_NORMALIZATION = 14,
  TANH = 15,
  FLOOR = 16,
  LOGISTIC = 17,
  PRELU = 18,
  POW = 19,
  NEG = 20,
  MINIMUM = 21,
  MAXIMUM = 22,
  LOG = 23,
  MIN = CONV_2D,
  MAX = LOG
};

inline const LayerType (&EnumValuesLayerType())[24] {
  static const LayerType values[] = {
    LayerType::CONV_2D,
    LayerType::AVERAGE_POOL_2D,
    LayerType::MAX_POOL_2D,
    LayerType::RELU,
    LayerType::SOFTMAX,
    LayerType::FULLY_CONNECTED,
    LayerType::ADD,
    LayerType::CONCATENATION,
    LayerType::DEPTHWISE_CONV_2D,
    LayerType::BATCH_TO_SPACE_ND,
    LayerType::SPACE_TO_BATCH_ND,
    LayerType::STRIDED_SLICE,
    LayerType::MUL,
    LayerType::DEQUANTIZE,
    LayerType::LOCAL_RESPONSE_NORMALIZATION,
    LayerType::TANH,
    LayerType::FLOOR,
    LayerType::LOGISTIC,
    LayerType::PRELU,
    LayerType::POW,
    LayerType::NEG,
    LayerType::MINIMUM,
    LayerType::MAXIMUM,
    LayerType::LOG
  };
  return values;
}

inline const char * const *EnumNamesLayerType() {
  static const char * const names[] = {
    "CONV_2D",
    "AVERAGE_POOL_2D",
    "MAX_POOL_2D",
    "RELU",
    "SOFTMAX",
    "FULLY_CONNECTED",
    "ADD",
    "CONCATENATION",
    "DEPTHWISE_CONV_2D",
    "BATCH_TO_SPACE_ND",
    "SPACE_TO_BATCH_ND",
    "STRIDED_SLICE",
    "MUL",
    "DEQUANTIZE",
    "LOCAL_RESPONSE_NORMALIZATION",
    "TANH",
    "FLOOR",
    "LOGISTIC",
    "PRELU",
    "POW",
    "NEG",
    "MINIMUM",
    "MAXIMUM",
    "LOG",
    nullptr
  };
  return names;
}

inline const char *EnumNameLayerType(LayerType e) {
  if (e < LayerType::CONV_2D || e > LayerType::LOG) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesLayerType()[index];
}

struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DATA_TYPE = 4,
    VT_INT8_DATA = 6,
    VT_FLOAT32_DATA = 8,
    VT_SHAPE = 10,
    VT_NAME = 12,
    VT_FLOAT16_DATA = 14,
    VT_BOOL8_DATA = 16,
    VT_INT32_DATA = 18
  };
  DataType data_type() const {
    return static_cast<DataType>(GetField<int8_t>(VT_DATA_TYPE, 0));
  }
  const flatbuffers::Vector<uint8_t> *int8_data() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_INT8_DATA);
  }
  const flatbuffers::Vector<float> *float32_data() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_FLOAT32_DATA);
  }
  const flatbuffers::Vector<uint32_t> *shape() const {
    return GetPointer<const flatbuffers::Vector<uint32_t> *>(VT_SHAPE);
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  /// since flatbuffers doesn't have float16 data type, use uint16 instead
  const flatbuffers::Vector<uint16_t> *float16_data() const {
    return GetPointer<const flatbuffers::Vector<uint16_t> *>(VT_FLOAT16_DATA);
  }
  const flatbuffers::Vector<uint8_t> *bool8_data() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_BOOL8_DATA);
  }
  const flatbuffers::Vector<int32_t> *int32_data() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_INT32_DATA);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, VT_DATA_TYPE) &&
           VerifyOffset(verifier, VT_INT8_DATA) &&
           verifier.VerifyVector(int8_data()) &&
           VerifyOffset(verifier, VT_FLOAT32_DATA) &&
           verifier.VerifyVector(float32_data()) &&
           VerifyOffset(verifier, VT_SHAPE) &&
           verifier.VerifyVector(shape()) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyOffset(verifier, VT_FLOAT16_DATA) &&
           verifier.VerifyVector(float16_data()) &&
           VerifyOffset(verifier, VT_BOOL8_DATA) &&
           verifier.VerifyVector(bool8_data()) &&
           VerifyOffset(verifier, VT_INT32_DATA) &&
           verifier.VerifyVector(int32_data()) &&
           verifier.EndTable();
  }
};

struct TensorBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_data_type(DataType data_type) {
    fbb_.AddElement<int8_t>(Tensor::VT_DATA_TYPE, static_cast<int8_t>(data_type), 0);
  }
  void add_int8_data(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> int8_data) {
    fbb_.AddOffset(Tensor::VT_INT8_DATA, int8_data);
  }
  void add_float32_data(flatbuffers::Offset<flatbuffers::Vector<float>> float32_data) {
    fbb_.AddOffset(Tensor::VT_FLOAT32_DATA, float32_data);
  }
  void add_shape(flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape) {
    fbb_.AddOffset(Tensor::VT_SHAPE, shape);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Tensor::VT_NAME, name);
  }
  void add_float16_data(flatbuffers::Offset<flatbuffers::Vector<uint16_t>> float16_data) {
    fbb_.AddOffset(Tensor::VT_FLOAT16_DATA, float16_data);
  }
  void add_bool8_data(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> bool8_data) {
    fbb_.AddOffset(Tensor::VT_BOOL8_DATA, bool8_data);
  }
  void add_int32_data(flatbuffers::Offset<flatbuffers::Vector<int32_t>> int32_data) {
    fbb_.AddOffset(Tensor::VT_INT32_DATA, int32_data);
  }
  explicit TensorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorBuilder &operator=(const TensorBuilder &);
  flatbuffers::Offset<Tensor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Tensor>(end);
    return o;
  }
};

inline flatbuffers::Offset<Tensor> CreateTensor(
    flatbuffers::FlatBufferBuilder &_fbb,
    DataType data_type = DataType::Float32,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> int8_data = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> float32_data = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint16_t>> float16_data = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> bool8_data = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> int32_data = 0) {
  TensorBuilder builder_(_fbb);
  builder_.add_int32_data(int32_data);
  builder_.add_bool8_data(bool8_data);
  builder_.add_float16_data(float16_data);
  builder_.add_name(name);
  builder_.add_shape(shape);
  builder_.add_float32_data(float32_data);
  builder_.add_int8_data(int8_data);
  builder_.add_data_type(data_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Tensor> CreateTensorDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    DataType data_type = DataType::Float32,
    const std::vector<uint8_t> *int8_data = nullptr,
    const std::vector<float> *float32_data = nullptr,
    const std::vector<uint32_t> *shape = nullptr,
    const char *name = nullptr,
    const std::vector<uint16_t> *float16_data = nullptr,
    const std::vector<uint8_t> *bool8_data = nullptr,
    const std::vector<int32_t> *int32_data = nullptr) {
  auto int8_data__ = int8_data ? _fbb.CreateVector<uint8_t>(*int8_data) : 0;
  auto float32_data__ = float32_data ? _fbb.CreateVector<float>(*float32_data) : 0;
  auto shape__ = shape ? _fbb.CreateVector<uint32_t>(*shape) : 0;
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto float16_data__ = float16_data ? _fbb.CreateVector<uint16_t>(*float16_data) : 0;
  auto bool8_data__ = bool8_data ? _fbb.CreateVector<uint8_t>(*bool8_data) : 0;
  auto int32_data__ = int32_data ? _fbb.CreateVector<int32_t>(*int32_data) : 0;
  return DNN::CreateTensor(
      _fbb,
      data_type,
      int8_data__,
      float32_data__,
      shape__,
      name__,
      float16_data__,
      bool8_data__,
      int32_data__);
}

/// For weights, and for features
struct QuantInfo FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NAME = 4,
    VT_DATA_TYPE = 6,
    VT_SCALES = 8,
    VT_ZERO_POINT = 10
  };
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  DataType data_type() const {
    return static_cast<DataType>(GetField<int8_t>(VT_DATA_TYPE, 0));
  }
  /// a float32 array of scales, the length will be 1 for non per-channel quantization, and be channelDim for per-channel quantization
  const flatbuffers::Vector<float> *scales() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_SCALES);
  }
  int32_t zero_point() const {
    return GetField<int32_t>(VT_ZERO_POINT, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyField<int8_t>(verifier, VT_DATA_TYPE) &&
           VerifyOffset(verifier, VT_SCALES) &&
           verifier.VerifyVector(scales()) &&
           VerifyField<int32_t>(verifier, VT_ZERO_POINT) &&
           verifier.EndTable();
  }
};

struct QuantInfoBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(QuantInfo::VT_NAME, name);
  }
  void add_data_type(DataType data_type) {
    fbb_.AddElement<int8_t>(QuantInfo::VT_DATA_TYPE, static_cast<int8_t>(data_type), 0);
  }
  void add_scales(flatbuffers::Offset<flatbuffers::Vector<float>> scales) {
    fbb_.AddOffset(QuantInfo::VT_SCALES, scales);
  }
  void add_zero_point(int32_t zero_point) {
    fbb_.AddElement<int32_t>(QuantInfo::VT_ZERO_POINT, zero_point, 0);
  }
  explicit QuantInfoBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  QuantInfoBuilder &operator=(const QuantInfoBuilder &);
  flatbuffers::Offset<QuantInfo> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<QuantInfo>(end);
    return o;
  }
};

inline flatbuffers::Offset<QuantInfo> CreateQuantInfo(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    DataType data_type = DataType::Float32,
    flatbuffers::Offset<flatbuffers::Vector<float>> scales = 0,
    int32_t zero_point = 0) {
  QuantInfoBuilder builder_(_fbb);
  builder_.add_zero_point(zero_point);
  builder_.add_scales(scales);
  builder_.add_name(name);
  builder_.add_data_type(data_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<QuantInfo> CreateQuantInfoDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *name = nullptr,
    DataType data_type = DataType::Float32,
    const std::vector<float> *scales = nullptr,
    int32_t zero_point = 0) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto scales__ = scales ? _fbb.CreateVector<float>(*scales) : 0;
  return DNN::CreateQuantInfo(
      _fbb,
      name__,
      data_type,
      scales__,
      zero_point);
}

struct Input FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SHAPE = 4,
    VT_NAME = 6
  };
  const flatbuffers::Vector<uint32_t> *shape() const {
    return GetPointer<const flatbuffers::Vector<uint32_t> *>(VT_SHAPE);
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_SHAPE) &&
           verifier.VerifyVector(shape()) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           verifier.EndTable();
  }
};

struct InputBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_shape(flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape) {
    fbb_.AddOffset(Input::VT_SHAPE, shape);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Input::VT_NAME, name);
  }
  explicit InputBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  InputBuilder &operator=(const InputBuilder &);
  flatbuffers::Offset<Input> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Input>(end);
    return o;
  }
};

inline flatbuffers::Offset<Input> CreateInput(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0) {
  InputBuilder builder_(_fbb);
  builder_.add_name(name);
  builder_.add_shape(shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<Input> CreateInputDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<uint32_t> *shape = nullptr,
    const char *name = nullptr) {
  auto shape__ = shape ? _fbb.CreateVector<uint32_t>(*shape) : 0;
  auto name__ = name ? _fbb.CreateString(name) : 0;
  return DNN::CreateInput(
      _fbb,
      shape__,
      name__);
}

struct CONV_2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_WEIGHT = 6,
    VT_BIAS = 8,
    VT_PADDING_LEFT = 10,
    VT_PADDING_RIGHT = 12,
    VT_PADDING_TOP = 14,
    VT_PADDING_BOTTOM = 16,
    VT_STRIDE_X = 18,
    VT_STRIDE_Y = 20,
    VT_FUSE = 22,
    VT_OUTPUT = 24
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *weight() const {
    return GetPointer<const flatbuffers::String *>(VT_WEIGHT);
  }
  const flatbuffers::String *bias() const {
    return GetPointer<const flatbuffers::String *>(VT_BIAS);
  }
  int32_t padding_left() const {
    return GetField<int32_t>(VT_PADDING_LEFT, 0);
  }
  int32_t padding_right() const {
    return GetField<int32_t>(VT_PADDING_RIGHT, 0);
  }
  int32_t padding_top() const {
    return GetField<int32_t>(VT_PADDING_TOP, 0);
  }
  int32_t padding_bottom() const {
    return GetField<int32_t>(VT_PADDING_BOTTOM, 0);
  }
  int32_t stride_x() const {
    return GetField<int32_t>(VT_STRIDE_X, 0);
  }
  int32_t stride_y() const {
    return GetField<int32_t>(VT_STRIDE_Y, 0);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyString(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyString(bias()) &&
           VerifyField<int32_t>(verifier, VT_PADDING_LEFT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_RIGHT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_TOP) &&
           VerifyField<int32_t>(verifier, VT_PADDING_BOTTOM) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_X) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_Y) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct CONV_2DBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(CONV_2D::VT_INPUT, input);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::String> weight) {
    fbb_.AddOffset(CONV_2D::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::String> bias) {
    fbb_.AddOffset(CONV_2D::VT_BIAS, bias);
  }
  void add_padding_left(int32_t padding_left) {
    fbb_.AddElement<int32_t>(CONV_2D::VT_PADDING_LEFT, padding_left, 0);
  }
  void add_padding_right(int32_t padding_right) {
    fbb_.AddElement<int32_t>(CONV_2D::VT_PADDING_RIGHT, padding_right, 0);
  }
  void add_padding_top(int32_t padding_top) {
    fbb_.AddElement<int32_t>(CONV_2D::VT_PADDING_TOP, padding_top, 0);
  }
  void add_padding_bottom(int32_t padding_bottom) {
    fbb_.AddElement<int32_t>(CONV_2D::VT_PADDING_BOTTOM, padding_bottom, 0);
  }
  void add_stride_x(int32_t stride_x) {
    fbb_.AddElement<int32_t>(CONV_2D::VT_STRIDE_X, stride_x, 0);
  }
  void add_stride_y(int32_t stride_y) {
    fbb_.AddElement<int32_t>(CONV_2D::VT_STRIDE_Y, stride_y, 0);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(CONV_2D::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(CONV_2D::VT_OUTPUT, output);
  }
  explicit CONV_2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  CONV_2DBuilder &operator=(const CONV_2DBuilder &);
  flatbuffers::Offset<CONV_2D> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<CONV_2D>(end);
    return o;
  }
};

inline flatbuffers::Offset<CONV_2D> CreateCONV_2D(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> weight = 0,
    flatbuffers::Offset<flatbuffers::String> bias = 0,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  CONV_2DBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_stride_y(stride_y);
  builder_.add_stride_x(stride_x);
  builder_.add_padding_bottom(padding_bottom);
  builder_.add_padding_top(padding_top);
  builder_.add_padding_right(padding_right);
  builder_.add_padding_left(padding_left);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<CONV_2D> CreateCONV_2DDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *weight = nullptr,
    const char *bias = nullptr,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto weight__ = weight ? _fbb.CreateString(weight) : 0;
  auto bias__ = bias ? _fbb.CreateString(bias) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateCONV_2D(
      _fbb,
      input__,
      weight__,
      bias__,
      padding_left,
      padding_right,
      padding_top,
      padding_bottom,
      stride_x,
      stride_y,
      fuse,
      output__);
}

struct AVERAGE_POOL_2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_PADDING_LEFT = 6,
    VT_PADDING_RIGHT = 8,
    VT_PADDING_TOP = 10,
    VT_PADDING_BOTTOM = 12,
    VT_STRIDE_X = 14,
    VT_STRIDE_Y = 16,
    VT_KERNEL_WIDTH = 18,
    VT_KERNEL_HEIGHT = 20,
    VT_FUSE = 22,
    VT_OUTPUT = 24
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  int32_t padding_left() const {
    return GetField<int32_t>(VT_PADDING_LEFT, 0);
  }
  int32_t padding_right() const {
    return GetField<int32_t>(VT_PADDING_RIGHT, 0);
  }
  int32_t padding_top() const {
    return GetField<int32_t>(VT_PADDING_TOP, 0);
  }
  int32_t padding_bottom() const {
    return GetField<int32_t>(VT_PADDING_BOTTOM, 0);
  }
  int32_t stride_x() const {
    return GetField<int32_t>(VT_STRIDE_X, 0);
  }
  int32_t stride_y() const {
    return GetField<int32_t>(VT_STRIDE_Y, 0);
  }
  int32_t kernel_width() const {
    return GetField<int32_t>(VT_KERNEL_WIDTH, 0);
  }
  int32_t kernel_height() const {
    return GetField<int32_t>(VT_KERNEL_HEIGHT, 0);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyField<int32_t>(verifier, VT_PADDING_LEFT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_RIGHT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_TOP) &&
           VerifyField<int32_t>(verifier, VT_PADDING_BOTTOM) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_X) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_Y) &&
           VerifyField<int32_t>(verifier, VT_KERNEL_WIDTH) &&
           VerifyField<int32_t>(verifier, VT_KERNEL_HEIGHT) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct AVERAGE_POOL_2DBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(AVERAGE_POOL_2D::VT_INPUT, input);
  }
  void add_padding_left(int32_t padding_left) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_PADDING_LEFT, padding_left, 0);
  }
  void add_padding_right(int32_t padding_right) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_PADDING_RIGHT, padding_right, 0);
  }
  void add_padding_top(int32_t padding_top) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_PADDING_TOP, padding_top, 0);
  }
  void add_padding_bottom(int32_t padding_bottom) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_PADDING_BOTTOM, padding_bottom, 0);
  }
  void add_stride_x(int32_t stride_x) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_STRIDE_X, stride_x, 0);
  }
  void add_stride_y(int32_t stride_y) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_STRIDE_Y, stride_y, 0);
  }
  void add_kernel_width(int32_t kernel_width) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_KERNEL_WIDTH, kernel_width, 0);
  }
  void add_kernel_height(int32_t kernel_height) {
    fbb_.AddElement<int32_t>(AVERAGE_POOL_2D::VT_KERNEL_HEIGHT, kernel_height, 0);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(AVERAGE_POOL_2D::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(AVERAGE_POOL_2D::VT_OUTPUT, output);
  }
  explicit AVERAGE_POOL_2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  AVERAGE_POOL_2DBuilder &operator=(const AVERAGE_POOL_2DBuilder &);
  flatbuffers::Offset<AVERAGE_POOL_2D> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<AVERAGE_POOL_2D>(end);
    return o;
  }
};

inline flatbuffers::Offset<AVERAGE_POOL_2D> CreateAVERAGE_POOL_2D(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    int32_t kernel_width = 0,
    int32_t kernel_height = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  AVERAGE_POOL_2DBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_kernel_height(kernel_height);
  builder_.add_kernel_width(kernel_width);
  builder_.add_stride_y(stride_y);
  builder_.add_stride_x(stride_x);
  builder_.add_padding_bottom(padding_bottom);
  builder_.add_padding_top(padding_top);
  builder_.add_padding_right(padding_right);
  builder_.add_padding_left(padding_left);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<AVERAGE_POOL_2D> CreateAVERAGE_POOL_2DDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    int32_t kernel_width = 0,
    int32_t kernel_height = 0,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateAVERAGE_POOL_2D(
      _fbb,
      input__,
      padding_left,
      padding_right,
      padding_top,
      padding_bottom,
      stride_x,
      stride_y,
      kernel_width,
      kernel_height,
      fuse,
      output__);
}

struct MAX_POOL_2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_PADDING_LEFT = 6,
    VT_PADDING_RIGHT = 8,
    VT_PADDING_TOP = 10,
    VT_PADDING_BOTTOM = 12,
    VT_STRIDE_X = 14,
    VT_STRIDE_Y = 16,
    VT_KERNEL_WIDTH = 18,
    VT_KERNEL_HEIGHT = 20,
    VT_FUSE = 22,
    VT_OUTPUT = 24
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  int32_t padding_left() const {
    return GetField<int32_t>(VT_PADDING_LEFT, 0);
  }
  int32_t padding_right() const {
    return GetField<int32_t>(VT_PADDING_RIGHT, 0);
  }
  int32_t padding_top() const {
    return GetField<int32_t>(VT_PADDING_TOP, 0);
  }
  int32_t padding_bottom() const {
    return GetField<int32_t>(VT_PADDING_BOTTOM, 0);
  }
  int32_t stride_x() const {
    return GetField<int32_t>(VT_STRIDE_X, 0);
  }
  int32_t stride_y() const {
    return GetField<int32_t>(VT_STRIDE_Y, 0);
  }
  int32_t kernel_width() const {
    return GetField<int32_t>(VT_KERNEL_WIDTH, 0);
  }
  int32_t kernel_height() const {
    return GetField<int32_t>(VT_KERNEL_HEIGHT, 0);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyField<int32_t>(verifier, VT_PADDING_LEFT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_RIGHT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_TOP) &&
           VerifyField<int32_t>(verifier, VT_PADDING_BOTTOM) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_X) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_Y) &&
           VerifyField<int32_t>(verifier, VT_KERNEL_WIDTH) &&
           VerifyField<int32_t>(verifier, VT_KERNEL_HEIGHT) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct MAX_POOL_2DBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(MAX_POOL_2D::VT_INPUT, input);
  }
  void add_padding_left(int32_t padding_left) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_PADDING_LEFT, padding_left, 0);
  }
  void add_padding_right(int32_t padding_right) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_PADDING_RIGHT, padding_right, 0);
  }
  void add_padding_top(int32_t padding_top) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_PADDING_TOP, padding_top, 0);
  }
  void add_padding_bottom(int32_t padding_bottom) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_PADDING_BOTTOM, padding_bottom, 0);
  }
  void add_stride_x(int32_t stride_x) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_STRIDE_X, stride_x, 0);
  }
  void add_stride_y(int32_t stride_y) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_STRIDE_Y, stride_y, 0);
  }
  void add_kernel_width(int32_t kernel_width) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_KERNEL_WIDTH, kernel_width, 0);
  }
  void add_kernel_height(int32_t kernel_height) {
    fbb_.AddElement<int32_t>(MAX_POOL_2D::VT_KERNEL_HEIGHT, kernel_height, 0);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(MAX_POOL_2D::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(MAX_POOL_2D::VT_OUTPUT, output);
  }
  explicit MAX_POOL_2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  MAX_POOL_2DBuilder &operator=(const MAX_POOL_2DBuilder &);
  flatbuffers::Offset<MAX_POOL_2D> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MAX_POOL_2D>(end);
    return o;
  }
};

inline flatbuffers::Offset<MAX_POOL_2D> CreateMAX_POOL_2D(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    int32_t kernel_width = 0,
    int32_t kernel_height = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  MAX_POOL_2DBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_kernel_height(kernel_height);
  builder_.add_kernel_width(kernel_width);
  builder_.add_stride_y(stride_y);
  builder_.add_stride_x(stride_x);
  builder_.add_padding_bottom(padding_bottom);
  builder_.add_padding_top(padding_top);
  builder_.add_padding_right(padding_right);
  builder_.add_padding_left(padding_left);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<MAX_POOL_2D> CreateMAX_POOL_2DDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    int32_t kernel_width = 0,
    int32_t kernel_height = 0,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateMAX_POOL_2D(
      _fbb,
      input__,
      padding_left,
      padding_right,
      padding_top,
      padding_bottom,
      stride_x,
      stride_y,
      kernel_width,
      kernel_height,
      fuse,
      output__);
}

struct RELU FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct RELUBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(RELU::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(RELU::VT_OUTPUT, output);
  }
  explicit RELUBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  RELUBuilder &operator=(const RELUBuilder &);
  flatbuffers::Offset<RELU> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<RELU>(end);
    return o;
  }
};

inline flatbuffers::Offset<RELU> CreateRELU(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  RELUBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<RELU> CreateRELUDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateRELU(
      _fbb,
      input__,
      output__);
}

struct SOFTMAX FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_BETA = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  float beta() const {
    return GetField<float>(VT_BETA, 0.0f);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyField<float>(verifier, VT_BETA) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct SOFTMAXBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(SOFTMAX::VT_INPUT, input);
  }
  void add_beta(float beta) {
    fbb_.AddElement<float>(SOFTMAX::VT_BETA, beta, 0.0f);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(SOFTMAX::VT_OUTPUT, output);
  }
  explicit SOFTMAXBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SOFTMAXBuilder &operator=(const SOFTMAXBuilder &);
  flatbuffers::Offset<SOFTMAX> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SOFTMAX>(end);
    return o;
  }
};

inline flatbuffers::Offset<SOFTMAX> CreateSOFTMAX(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    float beta = 0.0f,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  SOFTMAXBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_beta(beta);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<SOFTMAX> CreateSOFTMAXDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    float beta = 0.0f,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateSOFTMAX(
      _fbb,
      input__,
      beta,
      output__);
}

struct FULLY_CONNECTED FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_WEIGHT = 6,
    VT_BIAS = 8,
    VT_FUSE = 10,
    VT_OUTPUT = 12
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *weight() const {
    return GetPointer<const flatbuffers::String *>(VT_WEIGHT);
  }
  const flatbuffers::String *bias() const {
    return GetPointer<const flatbuffers::String *>(VT_BIAS);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyString(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyString(bias()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct FULLY_CONNECTEDBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(FULLY_CONNECTED::VT_INPUT, input);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::String> weight) {
    fbb_.AddOffset(FULLY_CONNECTED::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::String> bias) {
    fbb_.AddOffset(FULLY_CONNECTED::VT_BIAS, bias);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(FULLY_CONNECTED::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(FULLY_CONNECTED::VT_OUTPUT, output);
  }
  explicit FULLY_CONNECTEDBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  FULLY_CONNECTEDBuilder &operator=(const FULLY_CONNECTEDBuilder &);
  flatbuffers::Offset<FULLY_CONNECTED> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FULLY_CONNECTED>(end);
    return o;
  }
};

inline flatbuffers::Offset<FULLY_CONNECTED> CreateFULLY_CONNECTED(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> weight = 0,
    flatbuffers::Offset<flatbuffers::String> bias = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  FULLY_CONNECTEDBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<FULLY_CONNECTED> CreateFULLY_CONNECTEDDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *weight = nullptr,
    const char *bias = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto weight__ = weight ? _fbb.CreateString(weight) : 0;
  auto bias__ = bias ? _fbb.CreateString(bias) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateFULLY_CONNECTED(
      _fbb,
      input__,
      weight__,
      bias__,
      fuse,
      output__);
}

struct ADD FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT1 = 4,
    VT_INPUT2 = 6,
    VT_FUSE = 8,
    VT_OUTPUT = 10
  };
  const flatbuffers::String *input1() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT1);
  }
  const flatbuffers::String *input2() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT2);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT1) &&
           verifier.VerifyString(input1()) &&
           VerifyOffset(verifier, VT_INPUT2) &&
           verifier.VerifyString(input2()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct ADDBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input1(flatbuffers::Offset<flatbuffers::String> input1) {
    fbb_.AddOffset(ADD::VT_INPUT1, input1);
  }
  void add_input2(flatbuffers::Offset<flatbuffers::String> input2) {
    fbb_.AddOffset(ADD::VT_INPUT2, input2);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(ADD::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(ADD::VT_OUTPUT, output);
  }
  explicit ADDBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ADDBuilder &operator=(const ADDBuilder &);
  flatbuffers::Offset<ADD> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<ADD>(end);
    return o;
  }
};

inline flatbuffers::Offset<ADD> CreateADD(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input1 = 0,
    flatbuffers::Offset<flatbuffers::String> input2 = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  ADDBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input2(input2);
  builder_.add_input1(input1);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<ADD> CreateADDDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input1 = nullptr,
    const char *input2 = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  auto input1__ = input1 ? _fbb.CreateString(input1) : 0;
  auto input2__ = input2 ? _fbb.CreateString(input2) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateADD(
      _fbb,
      input1__,
      input2__,
      fuse,
      output__);
}

struct CONCATENATION FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUTS = 4,
    VT_AXIS = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *inputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_INPUTS);
  }
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUTS) &&
           verifier.VerifyVector(inputs()) &&
           verifier.VerifyVectorOfStrings(inputs()) &&
           VerifyField<int32_t>(verifier, VT_AXIS) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct CONCATENATIONBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> inputs) {
    fbb_.AddOffset(CONCATENATION::VT_INPUTS, inputs);
  }
  void add_axis(int32_t axis) {
    fbb_.AddElement<int32_t>(CONCATENATION::VT_AXIS, axis, 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(CONCATENATION::VT_OUTPUT, output);
  }
  explicit CONCATENATIONBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  CONCATENATIONBuilder &operator=(const CONCATENATIONBuilder &);
  flatbuffers::Offset<CONCATENATION> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<CONCATENATION>(end);
    return o;
  }
};

inline flatbuffers::Offset<CONCATENATION> CreateCONCATENATION(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> inputs = 0,
    int32_t axis = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  CONCATENATIONBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_axis(axis);
  builder_.add_inputs(inputs);
  return builder_.Finish();
}

inline flatbuffers::Offset<CONCATENATION> CreateCONCATENATIONDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *inputs = nullptr,
    int32_t axis = 0,
    const char *output = nullptr) {
  auto inputs__ = inputs ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*inputs) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateCONCATENATION(
      _fbb,
      inputs__,
      axis,
      output__);
}

struct DEPTHWISE_CONV_2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_WEIGHT = 6,
    VT_BIAS = 8,
    VT_PADDING_LEFT = 10,
    VT_PADDING_RIGHT = 12,
    VT_PADDING_TOP = 14,
    VT_PADDING_BOTTOM = 16,
    VT_STRIDE_X = 18,
    VT_STRIDE_Y = 20,
    VT_DEPTH_MULTIPLIER = 22,
    VT_FUSE = 24,
    VT_OUTPUT = 26
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *weight() const {
    return GetPointer<const flatbuffers::String *>(VT_WEIGHT);
  }
  const flatbuffers::String *bias() const {
    return GetPointer<const flatbuffers::String *>(VT_BIAS);
  }
  int32_t padding_left() const {
    return GetField<int32_t>(VT_PADDING_LEFT, 0);
  }
  int32_t padding_right() const {
    return GetField<int32_t>(VT_PADDING_RIGHT, 0);
  }
  int32_t padding_top() const {
    return GetField<int32_t>(VT_PADDING_TOP, 0);
  }
  int32_t padding_bottom() const {
    return GetField<int32_t>(VT_PADDING_BOTTOM, 0);
  }
  int32_t stride_x() const {
    return GetField<int32_t>(VT_STRIDE_X, 0);
  }
  int32_t stride_y() const {
    return GetField<int32_t>(VT_STRIDE_Y, 0);
  }
  int32_t depth_multiplier() const {
    return GetField<int32_t>(VT_DEPTH_MULTIPLIER, 0);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyString(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyString(bias()) &&
           VerifyField<int32_t>(verifier, VT_PADDING_LEFT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_RIGHT) &&
           VerifyField<int32_t>(verifier, VT_PADDING_TOP) &&
           VerifyField<int32_t>(verifier, VT_PADDING_BOTTOM) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_X) &&
           VerifyField<int32_t>(verifier, VT_STRIDE_Y) &&
           VerifyField<int32_t>(verifier, VT_DEPTH_MULTIPLIER) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct DEPTHWISE_CONV_2DBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(DEPTHWISE_CONV_2D::VT_INPUT, input);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::String> weight) {
    fbb_.AddOffset(DEPTHWISE_CONV_2D::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::String> bias) {
    fbb_.AddOffset(DEPTHWISE_CONV_2D::VT_BIAS, bias);
  }
  void add_padding_left(int32_t padding_left) {
    fbb_.AddElement<int32_t>(DEPTHWISE_CONV_2D::VT_PADDING_LEFT, padding_left, 0);
  }
  void add_padding_right(int32_t padding_right) {
    fbb_.AddElement<int32_t>(DEPTHWISE_CONV_2D::VT_PADDING_RIGHT, padding_right, 0);
  }
  void add_padding_top(int32_t padding_top) {
    fbb_.AddElement<int32_t>(DEPTHWISE_CONV_2D::VT_PADDING_TOP, padding_top, 0);
  }
  void add_padding_bottom(int32_t padding_bottom) {
    fbb_.AddElement<int32_t>(DEPTHWISE_CONV_2D::VT_PADDING_BOTTOM, padding_bottom, 0);
  }
  void add_stride_x(int32_t stride_x) {
    fbb_.AddElement<int32_t>(DEPTHWISE_CONV_2D::VT_STRIDE_X, stride_x, 0);
  }
  void add_stride_y(int32_t stride_y) {
    fbb_.AddElement<int32_t>(DEPTHWISE_CONV_2D::VT_STRIDE_Y, stride_y, 0);
  }
  void add_depth_multiplier(int32_t depth_multiplier) {
    fbb_.AddElement<int32_t>(DEPTHWISE_CONV_2D::VT_DEPTH_MULTIPLIER, depth_multiplier, 0);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(DEPTHWISE_CONV_2D::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(DEPTHWISE_CONV_2D::VT_OUTPUT, output);
  }
  explicit DEPTHWISE_CONV_2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  DEPTHWISE_CONV_2DBuilder &operator=(const DEPTHWISE_CONV_2DBuilder &);
  flatbuffers::Offset<DEPTHWISE_CONV_2D> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<DEPTHWISE_CONV_2D>(end);
    return o;
  }
};

inline flatbuffers::Offset<DEPTHWISE_CONV_2D> CreateDEPTHWISE_CONV_2D(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> weight = 0,
    flatbuffers::Offset<flatbuffers::String> bias = 0,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    int32_t depth_multiplier = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  DEPTHWISE_CONV_2DBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_depth_multiplier(depth_multiplier);
  builder_.add_stride_y(stride_y);
  builder_.add_stride_x(stride_x);
  builder_.add_padding_bottom(padding_bottom);
  builder_.add_padding_top(padding_top);
  builder_.add_padding_right(padding_right);
  builder_.add_padding_left(padding_left);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<DEPTHWISE_CONV_2D> CreateDEPTHWISE_CONV_2DDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *weight = nullptr,
    const char *bias = nullptr,
    int32_t padding_left = 0,
    int32_t padding_right = 0,
    int32_t padding_top = 0,
    int32_t padding_bottom = 0,
    int32_t stride_x = 0,
    int32_t stride_y = 0,
    int32_t depth_multiplier = 0,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto weight__ = weight ? _fbb.CreateString(weight) : 0;
  auto bias__ = bias ? _fbb.CreateString(bias) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateDEPTHWISE_CONV_2D(
      _fbb,
      input__,
      weight__,
      bias__,
      padding_left,
      padding_right,
      padding_top,
      padding_bottom,
      stride_x,
      stride_y,
      depth_multiplier,
      fuse,
      output__);
}

struct BATCH_TO_SPACE_ND FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_BLOCK_SIZES = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *block_sizes() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_BLOCK_SIZES);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_BLOCK_SIZES) &&
           verifier.VerifyVector(block_sizes()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct BATCH_TO_SPACE_NDBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(BATCH_TO_SPACE_ND::VT_INPUT, input);
  }
  void add_block_sizes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes) {
    fbb_.AddOffset(BATCH_TO_SPACE_ND::VT_BLOCK_SIZES, block_sizes);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(BATCH_TO_SPACE_ND::VT_OUTPUT, output);
  }
  explicit BATCH_TO_SPACE_NDBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  BATCH_TO_SPACE_NDBuilder &operator=(const BATCH_TO_SPACE_NDBuilder &);
  flatbuffers::Offset<BATCH_TO_SPACE_ND> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<BATCH_TO_SPACE_ND>(end);
    return o;
  }
};

inline flatbuffers::Offset<BATCH_TO_SPACE_ND> CreateBATCH_TO_SPACE_ND(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  BATCH_TO_SPACE_NDBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_block_sizes(block_sizes);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<BATCH_TO_SPACE_ND> CreateBATCH_TO_SPACE_NDDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *block_sizes = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto block_sizes__ = block_sizes ? _fbb.CreateVector<int32_t>(*block_sizes) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateBATCH_TO_SPACE_ND(
      _fbb,
      input__,
      block_sizes__,
      output__);
}

struct SPACE_TO_BATCH_ND FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_BLOCK_SIZES = 6,
    VT_PADS = 8,
    VT_OUTPUT = 10
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *block_sizes() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_BLOCK_SIZES);
  }
  const flatbuffers::Vector<int32_t> *pads() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_BLOCK_SIZES) &&
           verifier.VerifyVector(block_sizes()) &&
           VerifyOffset(verifier, VT_PADS) &&
           verifier.VerifyVector(pads()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct SPACE_TO_BATCH_NDBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(SPACE_TO_BATCH_ND::VT_INPUT, input);
  }
  void add_block_sizes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes) {
    fbb_.AddOffset(SPACE_TO_BATCH_ND::VT_BLOCK_SIZES, block_sizes);
  }
  void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
    fbb_.AddOffset(SPACE_TO_BATCH_ND::VT_PADS, pads);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(SPACE_TO_BATCH_ND::VT_OUTPUT, output);
  }
  explicit SPACE_TO_BATCH_NDBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SPACE_TO_BATCH_NDBuilder &operator=(const SPACE_TO_BATCH_NDBuilder &);
  flatbuffers::Offset<SPACE_TO_BATCH_ND> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SPACE_TO_BATCH_ND>(end);
    return o;
  }
};

inline flatbuffers::Offset<SPACE_TO_BATCH_ND> CreateSPACE_TO_BATCH_ND(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  SPACE_TO_BATCH_NDBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_pads(pads);
  builder_.add_block_sizes(block_sizes);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<SPACE_TO_BATCH_ND> CreateSPACE_TO_BATCH_NDDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *block_sizes = nullptr,
    const std::vector<int32_t> *pads = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto block_sizes__ = block_sizes ? _fbb.CreateVector<int32_t>(*block_sizes) : 0;
  auto pads__ = pads ? _fbb.CreateVector<int32_t>(*pads) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateSPACE_TO_BATCH_ND(
      _fbb,
      input__,
      block_sizes__,
      pads__,
      output__);
}

struct STRIDED_SLICE FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_STARTS = 6,
    VT_ENDS = 8,
    VT_STRIDES = 10,
    VT_BEGIN_MASK = 12,
    VT_END_MASK = 14,
    VT_SHRINK_AXIS_MASK = 16,
    VT_OUTPUT = 18
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *starts() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STARTS);
  }
  const flatbuffers::Vector<int32_t> *ends() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_ENDS);
  }
  const flatbuffers::Vector<int32_t> *strides() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDES);
  }
  int32_t begin_mask() const {
    return GetField<int32_t>(VT_BEGIN_MASK, 0);
  }
  int32_t end_mask() const {
    return GetField<int32_t>(VT_END_MASK, 0);
  }
  int32_t shrink_axis_mask() const {
    return GetField<int32_t>(VT_SHRINK_AXIS_MASK, 0);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_STARTS) &&
           verifier.VerifyVector(starts()) &&
           VerifyOffset(verifier, VT_ENDS) &&
           verifier.VerifyVector(ends()) &&
           VerifyOffset(verifier, VT_STRIDES) &&
           verifier.VerifyVector(strides()) &&
           VerifyField<int32_t>(verifier, VT_BEGIN_MASK) &&
           VerifyField<int32_t>(verifier, VT_END_MASK) &&
           VerifyField<int32_t>(verifier, VT_SHRINK_AXIS_MASK) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct STRIDED_SLICEBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(STRIDED_SLICE::VT_INPUT, input);
  }
  void add_starts(flatbuffers::Offset<flatbuffers::Vector<int32_t>> starts) {
    fbb_.AddOffset(STRIDED_SLICE::VT_STARTS, starts);
  }
  void add_ends(flatbuffers::Offset<flatbuffers::Vector<int32_t>> ends) {
    fbb_.AddOffset(STRIDED_SLICE::VT_ENDS, ends);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides) {
    fbb_.AddOffset(STRIDED_SLICE::VT_STRIDES, strides);
  }
  void add_begin_mask(int32_t begin_mask) {
    fbb_.AddElement<int32_t>(STRIDED_SLICE::VT_BEGIN_MASK, begin_mask, 0);
  }
  void add_end_mask(int32_t end_mask) {
    fbb_.AddElement<int32_t>(STRIDED_SLICE::VT_END_MASK, end_mask, 0);
  }
  void add_shrink_axis_mask(int32_t shrink_axis_mask) {
    fbb_.AddElement<int32_t>(STRIDED_SLICE::VT_SHRINK_AXIS_MASK, shrink_axis_mask, 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(STRIDED_SLICE::VT_OUTPUT, output);
  }
  explicit STRIDED_SLICEBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  STRIDED_SLICEBuilder &operator=(const STRIDED_SLICEBuilder &);
  flatbuffers::Offset<STRIDED_SLICE> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<STRIDED_SLICE>(end);
    return o;
  }
};

inline flatbuffers::Offset<STRIDED_SLICE> CreateSTRIDED_SLICE(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> starts = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> ends = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
    int32_t begin_mask = 0,
    int32_t end_mask = 0,
    int32_t shrink_axis_mask = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  STRIDED_SLICEBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_shrink_axis_mask(shrink_axis_mask);
  builder_.add_end_mask(end_mask);
  builder_.add_begin_mask(begin_mask);
  builder_.add_strides(strides);
  builder_.add_ends(ends);
  builder_.add_starts(starts);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<STRIDED_SLICE> CreateSTRIDED_SLICEDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *starts = nullptr,
    const std::vector<int32_t> *ends = nullptr,
    const std::vector<int32_t> *strides = nullptr,
    int32_t begin_mask = 0,
    int32_t end_mask = 0,
    int32_t shrink_axis_mask = 0,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto starts__ = starts ? _fbb.CreateVector<int32_t>(*starts) : 0;
  auto ends__ = ends ? _fbb.CreateVector<int32_t>(*ends) : 0;
  auto strides__ = strides ? _fbb.CreateVector<int32_t>(*strides) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateSTRIDED_SLICE(
      _fbb,
      input__,
      starts__,
      ends__,
      strides__,
      begin_mask,
      end_mask,
      shrink_axis_mask,
      output__);
}

struct MUL FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT1 = 4,
    VT_INPUT2 = 6,
    VT_FUSE = 8,
    VT_OUTPUT = 10
  };
  const flatbuffers::String *input1() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT1);
  }
  const flatbuffers::String *input2() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT2);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT1) &&
           verifier.VerifyString(input1()) &&
           VerifyOffset(verifier, VT_INPUT2) &&
           verifier.VerifyString(input2()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct MULBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input1(flatbuffers::Offset<flatbuffers::String> input1) {
    fbb_.AddOffset(MUL::VT_INPUT1, input1);
  }
  void add_input2(flatbuffers::Offset<flatbuffers::String> input2) {
    fbb_.AddOffset(MUL::VT_INPUT2, input2);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(MUL::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(MUL::VT_OUTPUT, output);
  }
  explicit MULBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  MULBuilder &operator=(const MULBuilder &);
  flatbuffers::Offset<MUL> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MUL>(end);
    return o;
  }
};

inline flatbuffers::Offset<MUL> CreateMUL(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input1 = 0,
    flatbuffers::Offset<flatbuffers::String> input2 = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  MULBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input2(input2);
  builder_.add_input1(input1);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<MUL> CreateMULDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input1 = nullptr,
    const char *input2 = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  auto input1__ = input1 ? _fbb.CreateString(input1) : 0;
  auto input2__ = input2 ? _fbb.CreateString(input2) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateMUL(
      _fbb,
      input1__,
      input2__,
      fuse,
      output__);
}

struct DEQUANTIZE FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct DEQUANTIZEBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(DEQUANTIZE::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(DEQUANTIZE::VT_OUTPUT, output);
  }
  explicit DEQUANTIZEBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  DEQUANTIZEBuilder &operator=(const DEQUANTIZEBuilder &);
  flatbuffers::Offset<DEQUANTIZE> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<DEQUANTIZE>(end);
    return o;
  }
};

inline flatbuffers::Offset<DEQUANTIZE> CreateDEQUANTIZE(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  DEQUANTIZEBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<DEQUANTIZE> CreateDEQUANTIZEDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateDEQUANTIZE(
      _fbb,
      input__,
      output__);
}

struct LOCAL_RESPONSE_NORMALIZATION FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_RADIUS = 6,
    VT_BIAS = 8,
    VT_ALPHA = 10,
    VT_BETA = 12,
    VT_OUTPUT = 14
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  int32_t radius() const {
    return GetField<int32_t>(VT_RADIUS, 0);
  }
  float bias() const {
    return GetField<float>(VT_BIAS, 0.0f);
  }
  float alpha() const {
    return GetField<float>(VT_ALPHA, 0.0f);
  }
  float beta() const {
    return GetField<float>(VT_BETA, 0.0f);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyField<int32_t>(verifier, VT_RADIUS) &&
           VerifyField<float>(verifier, VT_BIAS) &&
           VerifyField<float>(verifier, VT_ALPHA) &&
           VerifyField<float>(verifier, VT_BETA) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct LOCAL_RESPONSE_NORMALIZATIONBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(LOCAL_RESPONSE_NORMALIZATION::VT_INPUT, input);
  }
  void add_radius(int32_t radius) {
    fbb_.AddElement<int32_t>(LOCAL_RESPONSE_NORMALIZATION::VT_RADIUS, radius, 0);
  }
  void add_bias(float bias) {
    fbb_.AddElement<float>(LOCAL_RESPONSE_NORMALIZATION::VT_BIAS, bias, 0.0f);
  }
  void add_alpha(float alpha) {
    fbb_.AddElement<float>(LOCAL_RESPONSE_NORMALIZATION::VT_ALPHA, alpha, 0.0f);
  }
  void add_beta(float beta) {
    fbb_.AddElement<float>(LOCAL_RESPONSE_NORMALIZATION::VT_BETA, beta, 0.0f);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(LOCAL_RESPONSE_NORMALIZATION::VT_OUTPUT, output);
  }
  explicit LOCAL_RESPONSE_NORMALIZATIONBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  LOCAL_RESPONSE_NORMALIZATIONBuilder &operator=(const LOCAL_RESPONSE_NORMALIZATIONBuilder &);
  flatbuffers::Offset<LOCAL_RESPONSE_NORMALIZATION> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<LOCAL_RESPONSE_NORMALIZATION>(end);
    return o;
  }
};

inline flatbuffers::Offset<LOCAL_RESPONSE_NORMALIZATION> CreateLOCAL_RESPONSE_NORMALIZATION(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    int32_t radius = 0,
    float bias = 0.0f,
    float alpha = 0.0f,
    float beta = 0.0f,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  LOCAL_RESPONSE_NORMALIZATIONBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_beta(beta);
  builder_.add_alpha(alpha);
  builder_.add_bias(bias);
  builder_.add_radius(radius);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<LOCAL_RESPONSE_NORMALIZATION> CreateLOCAL_RESPONSE_NORMALIZATIONDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    int32_t radius = 0,
    float bias = 0.0f,
    float alpha = 0.0f,
    float beta = 0.0f,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateLOCAL_RESPONSE_NORMALIZATION(
      _fbb,
      input__,
      radius,
      bias,
      alpha,
      beta,
      output__);
}

struct TANH FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct TANHBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(TANH::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(TANH::VT_OUTPUT, output);
  }
  explicit TANHBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TANHBuilder &operator=(const TANHBuilder &);
  flatbuffers::Offset<TANH> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TANH>(end);
    return o;
  }
};

inline flatbuffers::Offset<TANH> CreateTANH(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  TANHBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<TANH> CreateTANHDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateTANH(
      _fbb,
      input__,
      output__);
}

struct FLOOR FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct FLOORBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(FLOOR::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(FLOOR::VT_OUTPUT, output);
  }
  explicit FLOORBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  FLOORBuilder &operator=(const FLOORBuilder &);
  flatbuffers::Offset<FLOOR> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FLOOR>(end);
    return o;
  }
};

inline flatbuffers::Offset<FLOOR> CreateFLOOR(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  FLOORBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<FLOOR> CreateFLOORDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateFLOOR(
      _fbb,
      input__,
      output__);
}

struct LOGISTIC FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct LOGISTICBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(LOGISTIC::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(LOGISTIC::VT_OUTPUT, output);
  }
  explicit LOGISTICBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  LOGISTICBuilder &operator=(const LOGISTICBuilder &);
  flatbuffers::Offset<LOGISTIC> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<LOGISTIC>(end);
    return o;
  }
};

inline flatbuffers::Offset<LOGISTIC> CreateLOGISTIC(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  LOGISTICBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<LOGISTIC> CreateLOGISTICDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateLOGISTIC(
      _fbb,
      input__,
      output__);
}

struct PRELU FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_ALPHA = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *alpha() const {
    return GetPointer<const flatbuffers::String *>(VT_ALPHA);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_ALPHA) &&
           verifier.VerifyString(alpha()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct PRELUBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(PRELU::VT_INPUT, input);
  }
  void add_alpha(flatbuffers::Offset<flatbuffers::String> alpha) {
    fbb_.AddOffset(PRELU::VT_ALPHA, alpha);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(PRELU::VT_OUTPUT, output);
  }
  explicit PRELUBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PRELUBuilder &operator=(const PRELUBuilder &);
  flatbuffers::Offset<PRELU> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<PRELU>(end);
    return o;
  }
};

inline flatbuffers::Offset<PRELU> CreatePRELU(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> alpha = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  PRELUBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_alpha(alpha);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<PRELU> CreatePRELUDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *alpha = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto alpha__ = alpha ? _fbb.CreateString(alpha) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreatePRELU(
      _fbb,
      input__,
      alpha__,
      output__);
}

struct POW FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_EXP = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *exp() const {
    return GetPointer<const flatbuffers::String *>(VT_EXP);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_EXP) &&
           verifier.VerifyString(exp()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct POWBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(POW::VT_INPUT, input);
  }
  void add_exp(flatbuffers::Offset<flatbuffers::String> exp) {
    fbb_.AddOffset(POW::VT_EXP, exp);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(POW::VT_OUTPUT, output);
  }
  explicit POWBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  POWBuilder &operator=(const POWBuilder &);
  flatbuffers::Offset<POW> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<POW>(end);
    return o;
  }
};

inline flatbuffers::Offset<POW> CreatePOW(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> exp = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  POWBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_exp(exp);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<POW> CreatePOWDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *exp = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto exp__ = exp ? _fbb.CreateString(exp) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreatePOW(
      _fbb,
      input__,
      exp__,
      output__);
}

struct NEG FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct NEGBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(NEG::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(NEG::VT_OUTPUT, output);
  }
  explicit NEGBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NEGBuilder &operator=(const NEGBuilder &);
  flatbuffers::Offset<NEG> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NEG>(end);
    return o;
  }
};

inline flatbuffers::Offset<NEG> CreateNEG(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  NEGBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<NEG> CreateNEGDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateNEG(
      _fbb,
      input__,
      output__);
}

struct MINIMUM FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT1 = 4,
    VT_INPUT2 = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::String *input1() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT1);
  }
  const flatbuffers::String *input2() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT2);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT1) &&
           verifier.VerifyString(input1()) &&
           VerifyOffset(verifier, VT_INPUT2) &&
           verifier.VerifyString(input2()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct MINIMUMBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input1(flatbuffers::Offset<flatbuffers::String> input1) {
    fbb_.AddOffset(MINIMUM::VT_INPUT1, input1);
  }
  void add_input2(flatbuffers::Offset<flatbuffers::String> input2) {
    fbb_.AddOffset(MINIMUM::VT_INPUT2, input2);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(MINIMUM::VT_OUTPUT, output);
  }
  explicit MINIMUMBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  MINIMUMBuilder &operator=(const MINIMUMBuilder &);
  flatbuffers::Offset<MINIMUM> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MINIMUM>(end);
    return o;
  }
};

inline flatbuffers::Offset<MINIMUM> CreateMINIMUM(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input1 = 0,
    flatbuffers::Offset<flatbuffers::String> input2 = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  MINIMUMBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input2(input2);
  builder_.add_input1(input1);
  return builder_.Finish();
}

inline flatbuffers::Offset<MINIMUM> CreateMINIMUMDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input1 = nullptr,
    const char *input2 = nullptr,
    const char *output = nullptr) {
  auto input1__ = input1 ? _fbb.CreateString(input1) : 0;
  auto input2__ = input2 ? _fbb.CreateString(input2) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateMINIMUM(
      _fbb,
      input1__,
      input2__,
      output__);
}

struct MAXIMUM FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT1 = 4,
    VT_INPUT2 = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::String *input1() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT1);
  }
  const flatbuffers::String *input2() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT2);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT1) &&
           verifier.VerifyString(input1()) &&
           VerifyOffset(verifier, VT_INPUT2) &&
           verifier.VerifyString(input2()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct MAXIMUMBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input1(flatbuffers::Offset<flatbuffers::String> input1) {
    fbb_.AddOffset(MAXIMUM::VT_INPUT1, input1);
  }
  void add_input2(flatbuffers::Offset<flatbuffers::String> input2) {
    fbb_.AddOffset(MAXIMUM::VT_INPUT2, input2);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(MAXIMUM::VT_OUTPUT, output);
  }
  explicit MAXIMUMBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  MAXIMUMBuilder &operator=(const MAXIMUMBuilder &);
  flatbuffers::Offset<MAXIMUM> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MAXIMUM>(end);
    return o;
  }
};

inline flatbuffers::Offset<MAXIMUM> CreateMAXIMUM(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input1 = 0,
    flatbuffers::Offset<flatbuffers::String> input2 = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  MAXIMUMBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input2(input2);
  builder_.add_input1(input1);
  return builder_.Finish();
}

inline flatbuffers::Offset<MAXIMUM> CreateMAXIMUMDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input1 = nullptr,
    const char *input2 = nullptr,
    const char *output = nullptr) {
  auto input1__ = input1 ? _fbb.CreateString(input1) : 0;
  auto input2__ = input2 ? _fbb.CreateString(input2) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateMAXIMUM(
      _fbb,
      input1__,
      input2__,
      output__);
}

struct LOG FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct LOGBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(LOG::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(LOG::VT_OUTPUT, output);
  }
  explicit LOGBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  LOGBuilder &operator=(const LOGBuilder &);
  flatbuffers::Offset<LOG> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<LOG>(end);
    return o;
  }
};

inline flatbuffers::Offset<LOG> CreateLOG(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  LOGBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<LOG> CreateLOGDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  auto input__ = input ? _fbb.CreateString(input) : 0;
  auto output__ = output ? _fbb.CreateString(output) : 0;
  return DNN::CreateLOG(
      _fbb,
      input__,
      output__);
}

struct Layer FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TYPE = 4,
    VT_CONV_2D_PARAM = 6,
    VT_AVERAGE_POOL_2D_PARAM = 8,
    VT_MAX_POOL_2D_PARAM = 10,
    VT_RELU_PARAM = 12,
    VT_SOFTMAX_PARAM = 14,
    VT_FULLY_CONNECTED_PARAM = 16,
    VT_ADD_PARAM = 18,
    VT_CONCATENATION_PARAM = 20,
    VT_DEPTHWISE_CONV_2D_PARAM = 22,
    VT_BATCH_TO_SPACE_ND_PARAM = 24,
    VT_SPACE_TO_BATCH_ND_PARAM = 26,
    VT_STRIDED_SLICE_PARAM = 28,
    VT_MUL_PARAM = 30,
    VT_DEQUANTIZE_PARAM = 32,
    VT_LOCAL_RESPONSE_NORMALIZATION_PARAM = 34,
    VT_TANH_PARAM = 36,
    VT_FLOOR_PARAM = 38,
    VT_LOGISTIC_PARAM = 40,
    VT_PRELU_PARAM = 42,
    VT_POW_PARAM = 44,
    VT_NEG_PARAM = 46,
    VT_MINIMUM_PARAM = 48,
    VT_MAXIMUM_PARAM = 50,
    VT_LOG_PARAM = 52
  };
  LayerType type() const {
    return static_cast<LayerType>(GetField<int8_t>(VT_TYPE, 0));
  }
  const CONV_2D *CONV_2D_param() const {
    return GetPointer<const CONV_2D *>(VT_CONV_2D_PARAM);
  }
  const AVERAGE_POOL_2D *AVERAGE_POOL_2D_param() const {
    return GetPointer<const AVERAGE_POOL_2D *>(VT_AVERAGE_POOL_2D_PARAM);
  }
  const MAX_POOL_2D *MAX_POOL_2D_param() const {
    return GetPointer<const MAX_POOL_2D *>(VT_MAX_POOL_2D_PARAM);
  }
  const RELU *RELU_param() const {
    return GetPointer<const RELU *>(VT_RELU_PARAM);
  }
  const SOFTMAX *SOFTMAX_param() const {
    return GetPointer<const SOFTMAX *>(VT_SOFTMAX_PARAM);
  }
  const FULLY_CONNECTED *FULLY_CONNECTED_param() const {
    return GetPointer<const FULLY_CONNECTED *>(VT_FULLY_CONNECTED_PARAM);
  }
  const ADD *ADD_param() const {
    return GetPointer<const ADD *>(VT_ADD_PARAM);
  }
  const CONCATENATION *CONCATENATION_param() const {
    return GetPointer<const CONCATENATION *>(VT_CONCATENATION_PARAM);
  }
  const DEPTHWISE_CONV_2D *DEPTHWISE_CONV_2D_param() const {
    return GetPointer<const DEPTHWISE_CONV_2D *>(VT_DEPTHWISE_CONV_2D_PARAM);
  }
  const BATCH_TO_SPACE_ND *BATCH_TO_SPACE_ND_param() const {
    return GetPointer<const BATCH_TO_SPACE_ND *>(VT_BATCH_TO_SPACE_ND_PARAM);
  }
  const SPACE_TO_BATCH_ND *SPACE_TO_BATCH_ND_param() const {
    return GetPointer<const SPACE_TO_BATCH_ND *>(VT_SPACE_TO_BATCH_ND_PARAM);
  }
  const STRIDED_SLICE *STRIDED_SLICE_param() const {
    return GetPointer<const STRIDED_SLICE *>(VT_STRIDED_SLICE_PARAM);
  }
  const MUL *MUL_param() const {
    return GetPointer<const MUL *>(VT_MUL_PARAM);
  }
  const DEQUANTIZE *DEQUANTIZE_param() const {
    return GetPointer<const DEQUANTIZE *>(VT_DEQUANTIZE_PARAM);
  }
  const LOCAL_RESPONSE_NORMALIZATION *LOCAL_RESPONSE_NORMALIZATION_param() const {
    return GetPointer<const LOCAL_RESPONSE_NORMALIZATION *>(VT_LOCAL_RESPONSE_NORMALIZATION_PARAM);
  }
  const TANH *TANH_param() const {
    return GetPointer<const TANH *>(VT_TANH_PARAM);
  }
  const FLOOR *FLOOR_param() const {
    return GetPointer<const FLOOR *>(VT_FLOOR_PARAM);
  }
  const LOGISTIC *LOGISTIC_param() const {
    return GetPointer<const LOGISTIC *>(VT_LOGISTIC_PARAM);
  }
  const PRELU *PRELU_param() const {
    return GetPointer<const PRELU *>(VT_PRELU_PARAM);
  }
  const POW *POW_param() const {
    return GetPointer<const POW *>(VT_POW_PARAM);
  }
  const NEG *NEG_param() const {
    return GetPointer<const NEG *>(VT_NEG_PARAM);
  }
  const MINIMUM *MINIMUM_param() const {
    return GetPointer<const MINIMUM *>(VT_MINIMUM_PARAM);
  }
  const MAXIMUM *MAXIMUM_param() const {
    return GetPointer<const MAXIMUM *>(VT_MAXIMUM_PARAM);
  }
  const LOG *LOG_param() const {
    return GetPointer<const LOG *>(VT_LOG_PARAM);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, VT_TYPE) &&
           VerifyOffset(verifier, VT_CONV_2D_PARAM) &&
           verifier.VerifyTable(CONV_2D_param()) &&
           VerifyOffset(verifier, VT_AVERAGE_POOL_2D_PARAM) &&
           verifier.VerifyTable(AVERAGE_POOL_2D_param()) &&
           VerifyOffset(verifier, VT_MAX_POOL_2D_PARAM) &&
           verifier.VerifyTable(MAX_POOL_2D_param()) &&
           VerifyOffset(verifier, VT_RELU_PARAM) &&
           verifier.VerifyTable(RELU_param()) &&
           VerifyOffset(verifier, VT_SOFTMAX_PARAM) &&
           verifier.VerifyTable(SOFTMAX_param()) &&
           VerifyOffset(verifier, VT_FULLY_CONNECTED_PARAM) &&
           verifier.VerifyTable(FULLY_CONNECTED_param()) &&
           VerifyOffset(verifier, VT_ADD_PARAM) &&
           verifier.VerifyTable(ADD_param()) &&
           VerifyOffset(verifier, VT_CONCATENATION_PARAM) &&
           verifier.VerifyTable(CONCATENATION_param()) &&
           VerifyOffset(verifier, VT_DEPTHWISE_CONV_2D_PARAM) &&
           verifier.VerifyTable(DEPTHWISE_CONV_2D_param()) &&
           VerifyOffset(verifier, VT_BATCH_TO_SPACE_ND_PARAM) &&
           verifier.VerifyTable(BATCH_TO_SPACE_ND_param()) &&
           VerifyOffset(verifier, VT_SPACE_TO_BATCH_ND_PARAM) &&
           verifier.VerifyTable(SPACE_TO_BATCH_ND_param()) &&
           VerifyOffset(verifier, VT_STRIDED_SLICE_PARAM) &&
           verifier.VerifyTable(STRIDED_SLICE_param()) &&
           VerifyOffset(verifier, VT_MUL_PARAM) &&
           verifier.VerifyTable(MUL_param()) &&
           VerifyOffset(verifier, VT_DEQUANTIZE_PARAM) &&
           verifier.VerifyTable(DEQUANTIZE_param()) &&
           VerifyOffset(verifier, VT_LOCAL_RESPONSE_NORMALIZATION_PARAM) &&
           verifier.VerifyTable(LOCAL_RESPONSE_NORMALIZATION_param()) &&
           VerifyOffset(verifier, VT_TANH_PARAM) &&
           verifier.VerifyTable(TANH_param()) &&
           VerifyOffset(verifier, VT_FLOOR_PARAM) &&
           verifier.VerifyTable(FLOOR_param()) &&
           VerifyOffset(verifier, VT_LOGISTIC_PARAM) &&
           verifier.VerifyTable(LOGISTIC_param()) &&
           VerifyOffset(verifier, VT_PRELU_PARAM) &&
           verifier.VerifyTable(PRELU_param()) &&
           VerifyOffset(verifier, VT_POW_PARAM) &&
           verifier.VerifyTable(POW_param()) &&
           VerifyOffset(verifier, VT_NEG_PARAM) &&
           verifier.VerifyTable(NEG_param()) &&
           VerifyOffset(verifier, VT_MINIMUM_PARAM) &&
           verifier.VerifyTable(MINIMUM_param()) &&
           VerifyOffset(verifier, VT_MAXIMUM_PARAM) &&
           verifier.VerifyTable(MAXIMUM_param()) &&
           VerifyOffset(verifier, VT_LOG_PARAM) &&
           verifier.VerifyTable(LOG_param()) &&
           verifier.EndTable();
  }
};

struct LayerBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(LayerType type) {
    fbb_.AddElement<int8_t>(Layer::VT_TYPE, static_cast<int8_t>(type), 0);
  }
  void add_CONV_2D_param(flatbuffers::Offset<CONV_2D> CONV_2D_param) {
    fbb_.AddOffset(Layer::VT_CONV_2D_PARAM, CONV_2D_param);
  }
  void add_AVERAGE_POOL_2D_param(flatbuffers::Offset<AVERAGE_POOL_2D> AVERAGE_POOL_2D_param) {
    fbb_.AddOffset(Layer::VT_AVERAGE_POOL_2D_PARAM, AVERAGE_POOL_2D_param);
  }
  void add_MAX_POOL_2D_param(flatbuffers::Offset<MAX_POOL_2D> MAX_POOL_2D_param) {
    fbb_.AddOffset(Layer::VT_MAX_POOL_2D_PARAM, MAX_POOL_2D_param);
  }
  void add_RELU_param(flatbuffers::Offset<RELU> RELU_param) {
    fbb_.AddOffset(Layer::VT_RELU_PARAM, RELU_param);
  }
  void add_SOFTMAX_param(flatbuffers::Offset<SOFTMAX> SOFTMAX_param) {
    fbb_.AddOffset(Layer::VT_SOFTMAX_PARAM, SOFTMAX_param);
  }
  void add_FULLY_CONNECTED_param(flatbuffers::Offset<FULLY_CONNECTED> FULLY_CONNECTED_param) {
    fbb_.AddOffset(Layer::VT_FULLY_CONNECTED_PARAM, FULLY_CONNECTED_param);
  }
  void add_ADD_param(flatbuffers::Offset<ADD> ADD_param) {
    fbb_.AddOffset(Layer::VT_ADD_PARAM, ADD_param);
  }
  void add_CONCATENATION_param(flatbuffers::Offset<CONCATENATION> CONCATENATION_param) {
    fbb_.AddOffset(Layer::VT_CONCATENATION_PARAM, CONCATENATION_param);
  }
  void add_DEPTHWISE_CONV_2D_param(flatbuffers::Offset<DEPTHWISE_CONV_2D> DEPTHWISE_CONV_2D_param) {
    fbb_.AddOffset(Layer::VT_DEPTHWISE_CONV_2D_PARAM, DEPTHWISE_CONV_2D_param);
  }
  void add_BATCH_TO_SPACE_ND_param(flatbuffers::Offset<BATCH_TO_SPACE_ND> BATCH_TO_SPACE_ND_param) {
    fbb_.AddOffset(Layer::VT_BATCH_TO_SPACE_ND_PARAM, BATCH_TO_SPACE_ND_param);
  }
  void add_SPACE_TO_BATCH_ND_param(flatbuffers::Offset<SPACE_TO_BATCH_ND> SPACE_TO_BATCH_ND_param) {
    fbb_.AddOffset(Layer::VT_SPACE_TO_BATCH_ND_PARAM, SPACE_TO_BATCH_ND_param);
  }
  void add_STRIDED_SLICE_param(flatbuffers::Offset<STRIDED_SLICE> STRIDED_SLICE_param) {
    fbb_.AddOffset(Layer::VT_STRIDED_SLICE_PARAM, STRIDED_SLICE_param);
  }
  void add_MUL_param(flatbuffers::Offset<MUL> MUL_param) {
    fbb_.AddOffset(Layer::VT_MUL_PARAM, MUL_param);
  }
  void add_DEQUANTIZE_param(flatbuffers::Offset<DEQUANTIZE> DEQUANTIZE_param) {
    fbb_.AddOffset(Layer::VT_DEQUANTIZE_PARAM, DEQUANTIZE_param);
  }
  void add_LOCAL_RESPONSE_NORMALIZATION_param(flatbuffers::Offset<LOCAL_RESPONSE_NORMALIZATION> LOCAL_RESPONSE_NORMALIZATION_param) {
    fbb_.AddOffset(Layer::VT_LOCAL_RESPONSE_NORMALIZATION_PARAM, LOCAL_RESPONSE_NORMALIZATION_param);
  }
  void add_TANH_param(flatbuffers::Offset<TANH> TANH_param) {
    fbb_.AddOffset(Layer::VT_TANH_PARAM, TANH_param);
  }
  void add_FLOOR_param(flatbuffers::Offset<FLOOR> FLOOR_param) {
    fbb_.AddOffset(Layer::VT_FLOOR_PARAM, FLOOR_param);
  }
  void add_LOGISTIC_param(flatbuffers::Offset<LOGISTIC> LOGISTIC_param) {
    fbb_.AddOffset(Layer::VT_LOGISTIC_PARAM, LOGISTIC_param);
  }
  void add_PRELU_param(flatbuffers::Offset<PRELU> PRELU_param) {
    fbb_.AddOffset(Layer::VT_PRELU_PARAM, PRELU_param);
  }
  void add_POW_param(flatbuffers::Offset<POW> POW_param) {
    fbb_.AddOffset(Layer::VT_POW_PARAM, POW_param);
  }
  void add_NEG_param(flatbuffers::Offset<NEG> NEG_param) {
    fbb_.AddOffset(Layer::VT_NEG_PARAM, NEG_param);
  }
  void add_MINIMUM_param(flatbuffers::Offset<MINIMUM> MINIMUM_param) {
    fbb_.AddOffset(Layer::VT_MINIMUM_PARAM, MINIMUM_param);
  }
  void add_MAXIMUM_param(flatbuffers::Offset<MAXIMUM> MAXIMUM_param) {
    fbb_.AddOffset(Layer::VT_MAXIMUM_PARAM, MAXIMUM_param);
  }
  void add_LOG_param(flatbuffers::Offset<LOG> LOG_param) {
    fbb_.AddOffset(Layer::VT_LOG_PARAM, LOG_param);
  }
  explicit LayerBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  LayerBuilder &operator=(const LayerBuilder &);
  flatbuffers::Offset<Layer> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Layer>(end);
    return o;
  }
};

inline flatbuffers::Offset<Layer> CreateLayer(
    flatbuffers::FlatBufferBuilder &_fbb,
    LayerType type = LayerType::CONV_2D,
    flatbuffers::Offset<CONV_2D> CONV_2D_param = 0,
    flatbuffers::Offset<AVERAGE_POOL_2D> AVERAGE_POOL_2D_param = 0,
    flatbuffers::Offset<MAX_POOL_2D> MAX_POOL_2D_param = 0,
    flatbuffers::Offset<RELU> RELU_param = 0,
    flatbuffers::Offset<SOFTMAX> SOFTMAX_param = 0,
    flatbuffers::Offset<FULLY_CONNECTED> FULLY_CONNECTED_param = 0,
    flatbuffers::Offset<ADD> ADD_param = 0,
    flatbuffers::Offset<CONCATENATION> CONCATENATION_param = 0,
    flatbuffers::Offset<DEPTHWISE_CONV_2D> DEPTHWISE_CONV_2D_param = 0,
    flatbuffers::Offset<BATCH_TO_SPACE_ND> BATCH_TO_SPACE_ND_param = 0,
    flatbuffers::Offset<SPACE_TO_BATCH_ND> SPACE_TO_BATCH_ND_param = 0,
    flatbuffers::Offset<STRIDED_SLICE> STRIDED_SLICE_param = 0,
    flatbuffers::Offset<MUL> MUL_param = 0,
    flatbuffers::Offset<DEQUANTIZE> DEQUANTIZE_param = 0,
    flatbuffers::Offset<LOCAL_RESPONSE_NORMALIZATION> LOCAL_RESPONSE_NORMALIZATION_param = 0,
    flatbuffers::Offset<TANH> TANH_param = 0,
    flatbuffers::Offset<FLOOR> FLOOR_param = 0,
    flatbuffers::Offset<LOGISTIC> LOGISTIC_param = 0,
    flatbuffers::Offset<PRELU> PRELU_param = 0,
    flatbuffers::Offset<POW> POW_param = 0,
    flatbuffers::Offset<NEG> NEG_param = 0,
    flatbuffers::Offset<MINIMUM> MINIMUM_param = 0,
    flatbuffers::Offset<MAXIMUM> MAXIMUM_param = 0,
    flatbuffers::Offset<LOG> LOG_param = 0) {
  LayerBuilder builder_(_fbb);
  builder_.add_LOG_param(LOG_param);
  builder_.add_MAXIMUM_param(MAXIMUM_param);
  builder_.add_MINIMUM_param(MINIMUM_param);
  builder_.add_NEG_param(NEG_param);
  builder_.add_POW_param(POW_param);
  builder_.add_PRELU_param(PRELU_param);
  builder_.add_LOGISTIC_param(LOGISTIC_param);
  builder_.add_FLOOR_param(FLOOR_param);
  builder_.add_TANH_param(TANH_param);
  builder_.add_LOCAL_RESPONSE_NORMALIZATION_param(LOCAL_RESPONSE_NORMALIZATION_param);
  builder_.add_DEQUANTIZE_param(DEQUANTIZE_param);
  builder_.add_MUL_param(MUL_param);
  builder_.add_STRIDED_SLICE_param(STRIDED_SLICE_param);
  builder_.add_SPACE_TO_BATCH_ND_param(SPACE_TO_BATCH_ND_param);
  builder_.add_BATCH_TO_SPACE_ND_param(BATCH_TO_SPACE_ND_param);
  builder_.add_DEPTHWISE_CONV_2D_param(DEPTHWISE_CONV_2D_param);
  builder_.add_CONCATENATION_param(CONCATENATION_param);
  builder_.add_ADD_param(ADD_param);
  builder_.add_FULLY_CONNECTED_param(FULLY_CONNECTED_param);
  builder_.add_SOFTMAX_param(SOFTMAX_param);
  builder_.add_RELU_param(RELU_param);
  builder_.add_MAX_POOL_2D_param(MAX_POOL_2D_param);
  builder_.add_AVERAGE_POOL_2D_param(AVERAGE_POOL_2D_param);
  builder_.add_CONV_2D_param(CONV_2D_param);
  builder_.add_type(type);
  return builder_.Finish();
}

struct Model FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_LAYERS = 4,
    VT_INITIALIZERS = 6,
    VT_INPUTS = 8,
    VT_QUANT_INFOS = 10,
    VT_OUTPUTS = 12,
    VT_VERSION = 14
  };
  const flatbuffers::Vector<flatbuffers::Offset<Layer>> *layers() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Layer>> *>(VT_LAYERS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<Tensor>> *initializers() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Tensor>> *>(VT_INITIALIZERS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<Input>> *inputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Input>> *>(VT_INPUTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<QuantInfo>> *quant_infos() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<QuantInfo>> *>(VT_QUANT_INFOS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *outputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_OUTPUTS);
  }
  uint32_t version() const {
    return GetField<uint32_t>(VT_VERSION, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_LAYERS) &&
           verifier.VerifyVector(layers()) &&
           verifier.VerifyVectorOfTables(layers()) &&
           VerifyOffset(verifier, VT_INITIALIZERS) &&
           verifier.VerifyVector(initializers()) &&
           verifier.VerifyVectorOfTables(initializers()) &&
           VerifyOffset(verifier, VT_INPUTS) &&
           verifier.VerifyVector(inputs()) &&
           verifier.VerifyVectorOfTables(inputs()) &&
           VerifyOffset(verifier, VT_QUANT_INFOS) &&
           verifier.VerifyVector(quant_infos()) &&
           verifier.VerifyVectorOfTables(quant_infos()) &&
           VerifyOffset(verifier, VT_OUTPUTS) &&
           verifier.VerifyVector(outputs()) &&
           verifier.VerifyVectorOfStrings(outputs()) &&
           VerifyField<uint32_t>(verifier, VT_VERSION) &&
           verifier.EndTable();
  }
};

struct ModelBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_layers(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Layer>>> layers) {
    fbb_.AddOffset(Model::VT_LAYERS, layers);
  }
  void add_initializers(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Tensor>>> initializers) {
    fbb_.AddOffset(Model::VT_INITIALIZERS, initializers);
  }
  void add_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Input>>> inputs) {
    fbb_.AddOffset(Model::VT_INPUTS, inputs);
  }
  void add_quant_infos(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<QuantInfo>>> quant_infos) {
    fbb_.AddOffset(Model::VT_QUANT_INFOS, quant_infos);
  }
  void add_outputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> outputs) {
    fbb_.AddOffset(Model::VT_OUTPUTS, outputs);
  }
  void add_version(uint32_t version) {
    fbb_.AddElement<uint32_t>(Model::VT_VERSION, version, 0);
  }
  explicit ModelBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ModelBuilder &operator=(const ModelBuilder &);
  flatbuffers::Offset<Model> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Model>(end);
    return o;
  }
};

inline flatbuffers::Offset<Model> CreateModel(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Layer>>> layers = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Tensor>>> initializers = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Input>>> inputs = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<QuantInfo>>> quant_infos = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> outputs = 0,
    uint32_t version = 0) {
  ModelBuilder builder_(_fbb);
  builder_.add_version(version);
  builder_.add_outputs(outputs);
  builder_.add_quant_infos(quant_infos);
  builder_.add_inputs(inputs);
  builder_.add_initializers(initializers);
  builder_.add_layers(layers);
  return builder_.Finish();
}

inline flatbuffers::Offset<Model> CreateModelDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<flatbuffers::Offset<Layer>> *layers = nullptr,
    const std::vector<flatbuffers::Offset<Tensor>> *initializers = nullptr,
    const std::vector<flatbuffers::Offset<Input>> *inputs = nullptr,
    const std::vector<flatbuffers::Offset<QuantInfo>> *quant_infos = nullptr,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *outputs = nullptr,
    uint32_t version = 0) {
  auto layers__ = layers ? _fbb.CreateVector<flatbuffers::Offset<Layer>>(*layers) : 0;
  auto initializers__ = initializers ? _fbb.CreateVector<flatbuffers::Offset<Tensor>>(*initializers) : 0;
  auto inputs__ = inputs ? _fbb.CreateVector<flatbuffers::Offset<Input>>(*inputs) : 0;
  auto quant_infos__ = quant_infos ? _fbb.CreateVector<flatbuffers::Offset<QuantInfo>>(*quant_infos) : 0;
  auto outputs__ = outputs ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*outputs) : 0;
  return DNN::CreateModel(
      _fbb,
      layers__,
      initializers__,
      inputs__,
      quant_infos__,
      outputs__,
      version);
}

inline const DNN::Model *GetModel(const void *buf) {
  return flatbuffers::GetRoot<DNN::Model>(buf);
}

inline const DNN::Model *GetSizePrefixedModel(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<DNN::Model>(buf);
}

inline bool VerifyModelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<DNN::Model>(nullptr);
}

inline bool VerifySizePrefixedModelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<DNN::Model>(nullptr);
}

inline void FinishModelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<DNN::Model> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedModelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<DNN::Model> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace DNN

#endif  // FLATBUFFERS_GENERATED_DAQ_DNN_H_
